## 확률

# 확률은 경우의 수에서 생각할 수 있는 모든 경우의 수 중에 우리가 관심을 갖는 경우의 수가 차지 하는 비율로 생각할수 있다.

## ==용어==
## - 시행 : 다양한 결과가 나올수 있는 어떤 것을 실제로 하는 것을 말한다.
#       ex) 주사위 던진다, 복권을 긁는다.
# - 표본 공간 : 가능한 모든 결과의 모임.
#       ex) 동전 던지기의 경우 한번 던지면 (앞,뒤)
#           두번 던지면 {(앞,앞)(앞,뒤)(뒤,앞),(뒤,뒤)}, 814만분의 1이 표본 공간
# - 사건 : 가능한 결과들 중 어떤 요구사항을 만족하는 것.
#       ex) 로또 추첨 결과 "여섯개의 숫자가 연속이다", "모두 홀수가 나온다"... 등
#           중요한것은 "사건이 단 하나의 결과를 의미하지 않을 수도 있다는 점...."
# - 배반 사건 : 사건이 동시에 일어날수 없는 두 사건간의 관계를 배반 사건이라고 한다.
#       ex) 복권에서 "모두 짝수이다", "모두 홀수이다"는 동시에 일어날수 없다.
# - 여사건 : 어떤 사건이 일어나지 않는 것을 말함.
#       ex) 사건 A에 대해서 A가 일어나지 않는다고 하는 사건. 표본 공간의 부분 집합으로서 생각하면 A의 여집합임.
#           복권 추첨결과가 "모든 숫자가 짝수다"의 여사건은 "모든 숫자가 짝수인것은 아니다."
#           즉, "적어도 하나는 홀수이다."
# 수학적으로는 이들을 모두 집합으로 표현할 수 있다.
# 사건은 표본공간의 부분집합으로 정의, 공집합도 표본공간의 부분집합이기 때문에 사건....

### 수학적 확률
# 수학적이 확률은 어떤 가능한 모든 결과의 개수로 표현할수 있다.
# 주사위를 두번 던졌을 경우 모든 경우의 수는 6 * 6 = 36, "두 값을 곱했을 때 홀수가 나온다."
# 사건을 생각해보면 두 값을 곱했을 경우, 두값 모두 홀수여야 한다. 이때 경우의 수는 3 * 3 = 9
# 수학적 확률 계산은 9/36 이것은 0.25% 가 됨을 알수 있다.
# 다만, 여기서 중요한 포인트는 표본공간의 모든 경우가 나올수 있는 가능성은 같아야 한다.
# 이 조건이 만족되어야 한다.

### 통계적 확률
# 통계적 확률은 수학적 확률에 비해 더 구체적으로 접근한다.
# 통계적 확률을 "전체 시행 횟수중 특정 사건이 일어나는 횟수의 비율로 표현"
# 전체 시행 횟수는n이라고 하고, 특정 사건이 일어날 횟수를 r이라고 하면 그 사건이 일어날 비율은 r/n이 된다.
# 일반적으로 통계적 확률은 수학적 확률과 정확히 일치하지 않는다.
# 대신 횟수를 무한정 늘리면 통계적 확률은 결국 수학적 확률에 근접하게 된다.

### 극한의 의미
# 통계적 확률이 수학적 확률에 한없이 가까워 진다는 이야기는 시행 횟수가 무한정 늘어나는 극한을 가정하기 때문이다.
# 두가지 의미와 관련되어 있다.
# 첫번째, 시행 횟수를 무한히 늘렸을때, 수학적 확률에 통계적 확률이 근접한다.
#   하지만, 시행 횟수가 적다면 우연에 의해서 수학적 확률에 벗어나는 경우가 종종 생긴다는 점이다.
#   통계학에서는 이것을 표집오차(sampling Error)라고 한다. 이것은 시행 횟수가 늘어날수록 점점 줄어드는 성질이 있다.
#   결국에는 0에 매우 가까워 진다는 것이다.
# 두번째, 한없이 가까워 진다. 가까워진다는 말은 두가지 의미를 포함한다. 수학적 확률과 통계적 확률간의 차이가 0에 가까워진다.
#   단 절대로 0이 된다는것은 아님.

### 큰 수의 법칙
# 큰수의 법칙(Law of large number)은 실제 자료의 값으로 계산한 평균,
# 즉 표본평균이 자료의 크기 커짐에 따라서 한없이 특정 값에 가까워진다는것을 말함.
# 여기서 특정값은 확률 용어로 기댓값(Expected Value)을 말한다.
# 통계적 확률은 큰 수의 법칙의 특수한 경우에 지나지 않는데 이유는 비율 자체가 일종의 표본 평균이기 때문이다.
# 특정값이 나오는 결과값의 합에 시행횟수로 나누면 이건 통계적 확률이 되고, 이것은 기록된 값의 평균이기도 하다.
# 애초 평균이란 자료의 총합을 자료의 개수로 나눠준 것이기 때문이다. 즉, 큰수의 법칙이 적용된다는 것이다.
# 시행 횟수가 많아질수록 성공 비율 또는 통계적 확률을 기대값에 가까워진다는 것을 알수 있다.
# 여기서 말하는 기댓값은 수학적 확률을 의미함.

# 동전을 5회 던졌을 때의 경우의 예
# 앞 : 1, 뒤 : 0
# 시행 값 : 1 0 0 0 1
# 총합 : 2
# 평균 : 2/5 = 0.4

# 동전을 20회 던졌을 경우
# # 앞 : 1, 뒤 : 0
# 시행 값 : 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1
# 총합 : 11
# 평균 : 11/20 = 0.55

## R을 이용한 시뮬레이션
# 동전 던지기 결과는 가능한 경우 두가지 - 앞면, 뒷면이고 이 둘은 서로의 여사건 관계이다.
# 따라서 이들의 확률은 앞면이 나올 확률만 정하면 뒷면이 나올 확률은 1에서 앞면이 나올 확률을 빼면 된다.
## 이때 확률을 P라고 하면, 이렇게 가능한 결과는 두개 밖에 없고,
## 성공 확률이 정해져 있는 확률 시행을 "베르누이 시행(Bernoulli trial)"이라고 한다.
# 베르누이 시행(Bernoulli trial 또는 binomial trial)은
# 확률론과 통계학에서 임의의 결과가 '성공' 또는 '실패'의 두 가지 중 하나인 실험을 뜻한다.
# 다시 말해 '예' 또는 '아니오' 중 하나의 결과를 낳는 실험을 말한다.

# R에서 사용하는 베르누이 시행 함수 rbinom()
# r의 의미는 랜덤을 의미함, R에서 확률적 난수를 생성하는 것을 의미하는 것으로 사용함.
# binom은 우리말로 이항이라고 번역되는 binominal단어의 축약형이다.
# 베르누이 시행은 이항시행의 일종이다. 차이는 베르누이 시행에선 한번만, 이항 시행에서는 여러번 할수 있다는 점

## rbinom()함수 형식
## rbinom(난수의 개수, 시행횟수, 성공 확률)
# 난수 갯수는 난수의 갯수를 의미로 앞에 설명한 백터에 저장된다.
# 성공 확률은 0과 1사이의 숫자를 사용함.

# 동전 던지기 : 5번 던진 결과, 그 확률 0.5, 0은 실패 1은 성공....
x <- rbinom(100000, 1, 0.5) # 시행 결과
mean(x)

## 수학적 확률로 확률문제 풀기
# 문제) 1~5까지 숫자 카드를 섞어서 세장의 카드를 뽑아 세자리의 숫자를 만들때에 그 결과가 320보다 클 확률은 얼마인가?
# 전제 조건 : 각각의 카드가 뽑힐 확률은 같다는 것...
# 순열을 이용하여 계산....
# nPr, n = 5, r = 3, 5 * 4 * 3 = 60, 전체 경우의 수 : 60
# 이중에 우리가 원하는 경우의 수는 320보다 큰 수의 값을 가지는 경우
# 앞 첫자리의 숫자는 3~5 이상이여야 조건에 충족된다. 
# 앞 첫차리가 숫자 4와 5는 뒤에 나오는 숫자와 상관없이 조건을 충족
# 앞 4와 5일때 경우의 수 구하기 각각 경우의 수는 nPr => n=4 ,r=2 => 4*3 = 12
# 앞 첫자리가 3인 경우, 두번째 자리의 숫자가 1이 되면 안됨.(조건 충족 x)
# 앞 첫자리가 3이고, 두번째가 1일 경우의 수는 3이다. 전체 3일때 경우수 - 두번째 1일 경우의 값은 9가 나온다.
# 12 + 12 + 9 = 33
# 수학적 확률은 전체 경우의 수 33/60 = 0.55가 된다.

## 통계적 확률로 문제 풀기 : 시뮬레이션
# 앞의 수학적 내용을 알지 못해도 풀수 있는 방법이 존재한다.
# "시행 횟수가 늘어남에 따라 통계적 확률은 수학적 확률에 한없이 가까워 진다는 사실"을 이용
# 장점은 모두 경우의 수를 다 컴토해야 하는 수고를 덜수 있고,
# 특히 경우의 수를 세기가 매우 복잡한 문제에서 더 유용하게 사용된다.

## 시뮬레이션 시행은 R프로그램을 이용하여 1~5까지의 숫자 3개를 뽑아서 그 값이 320보다 큰 경우를 구하는 시뮬레이션을 진행할수 있다. 
# 이 시뮬레이션을 충분히 진행하여 비율을 계산하면 그게 통계적 확률이 되고, 이는 수학적 확률에 근사하게 된다.

## 수학적인 공식을 적용하지 않고 확률을 계산하는 방법을 "몬테카를로 시뮬레이션"이라고 한다.
## "몬테카를로 방법"

## 시행을 위해서 R에서 따로 프로그램을 하지 않아도 된다. sample()이라는 함수가 존재
## sample(추첨할 대상, 추첨할 개수, 복원 추출 여부)
# 복원 추출은 뽑은 것을 원래 대로 돌려 놓는 것을 의미함. 여기서는 비복원 추출을한다.
# 여기서는 sample(1:5,3,replace=F) -> 1~5까지의 숫자를 3개 뽑아서 샘플을 작성(비복원)
n_simulation <- 1000
n_success <- 0 

for (i in 1:n_simulation){
    x <- sample(1:5,3,replace = F)
    if (x[1] >= 4) n_success <- n_success + 1
    if ((x[1] == 3) & (x[2] >= 2)) n_success <- n_success + 1

}
print(n_success)
stc <- n_success/ n_simulation
print(stc)

## 몬테카를로 방법을 사용하여 원주율 계산...
# 원주율 : 3.14...
## 시뮬레이션을 통해서 원주율을 구하고,,, 실제 원주율과 비교
## X과 Y축을 중심으로 2차원 좌표 평면을 생각합니다. 가로축과 세로축의 길이가 1인 정사각형을 생각합니다.
#   이 정사각형을 통해 원점을 중심으로 반지름이 1인 원을 그리면 온전한 원이 아닌 1/4인 사분원이 된다.
#   가로 세로 길이가 1인 정사각형에 매우 작은 입자를 뿌린다고 생각합니다.(균등하게 랜덤하게)
#   이 경우에 사분원 안쪽으로 떨어지는 경우도 있고, 아닌 경우도 있을것입니다.
#   이 입자는 무작위로 뿌립니다고 가정하고, 안쪽에 뿌려진 입자의 비율은 정사각형의 넓이에서 사분원이 차지하는 넓이의 비율이라고 추측
#   이 경우 오차가 생길수 있으나, 입자를 충분히 많이 촘촘하게 뿌린다면, 이 통계적 확률은 수학적 확률에 가깝게 됩니다.
#   여기에 원의 넓이를 구하는 식을 도입, 파이*반지름의 제곱 이걸 4분원이기 때문에 1/4로 계산해야합니다.
#   결국 반지름은 1이기 때문에 파이/4 즉, 입자가 사분원 안에 떨어지는것의 비율은 파이/4와 가깝게 된다.
#   구해진 값에 4를 곱하면, 파이 , 즉 원주율을 구할수 있게 된다.

## R에서 이런 동작을 하는 runif(1)
## 이 함수는 0에서 1사이의 무작위 숫자 하나를 선택, 이것을 좌표x,y에 대입하면 입자를 무작위로 뿌리는 것과 같은 효과를 가져옴

n_sim <- 1000
x <- vector(length = n_sim) # vertor()함수 : 리스트를 1000개를 만들어 놓은것과 같다(저장할 공간)
y <- vector(length = n_sim) 
res <- 0
for (i in 1:n_sim){
    x[i] <- runif(1)
    y[i] <- runif(1)
    # 1미만이면 원안에 들어간다.
    if (x[i]^2 + y[i]^2 < 1) res <- res + 1
}
print(res)
print(4 * res / n_sim)
 

circle <- function(x) sqrt(1 - x^2)
plot(x, y, xlab = "X", ylab= "Y")
curve(circle, from=0, to=1, add=T, col="blue", lwd=2)

## 몬티홀 문제...

## 바꾸지 않고 처음 문을 고른 경우
n_simul <- 1000
doors <- 1:3
success <- 0
for (i in 1:n_simul){
    # 3개의 문 중에 차의 위치를 선택
    car <- sample(doors,1)  
    # 차가 없는 곳에 염소들을 배치
    if (car == 1){
        goat <- c(2,3)
    }else if (car ==2) {
       goat <- c(1,3)
    }else{
        goat <- c(1,2)
    }
    # 참가자가 문을 선택(고른다)
    pick <- sample(doors,1)

    # 참가자가 고르지 않은 문중 염소가 있는 문을 찾는다.
    goat_not_picked <- goat[goat != pick]
    # 참가자가 고르지 않은 문중 염소가 있는 문 하나를 열어준다.
    if (length(goat_not_picked) > 1) {
        open <- sample(goat_not_picked,1)

    }else {
        open <- goat_not_picked
    }
    # 바꾸지 않고 처음 고른 문이 차가 있는 문이면 "성공"을 기록
    if (pick == car) success <- success + 1
}
# 총 시행중 "성공의 비율"
success / n_simul



## 바꿨을 경우 
n_simul <- 1000
doors <- 1:3
success <- 0
for (i in 1:n_simul){
    # 3개의 문 중에 차의 위치를 선택
    car <- sample(doors,1)  
    # 차가 없는 곳에 염소들을 배치
    if (car == 1){
        goat <- c(2,3)
    }else if (car ==2) {
       goat <- c(1,3)
    }else{
        goat <- c(1,2)
    }
    # 참가자가 문을 선택(고른다)
    pick <- sample(doors,1)

    # 참가자가 고르지 않은 문중 염소가 있는 문을 찾는다.
    goat_not_picked <- goat[goat != pick]
    # 참가자가 고르지 않은 문중 염소가 있는 문 하나를 열어준다.
    if (length(goat_not_picked) > 1) {
        open <- sample(goat_not_picked,1)

    }else {
        open <- goat_not_picked
    }
    # 바꾸어 선택한 문이 차가 있는 문이면 "성공"을 기록
    pick <- doors[(doors != pick) & (doors != open)]
    if (pick == car) success <- success + 1  
    
}
# 총 시행중 "성공"의 비율 
success / n_simul

### 심슨의 역설



### 생일 역설 : 왜 드물게 보이는 사건은 꼭 일어나는가?
# 한번에 20 명의 학생이 있을 때에 생일이 겹치는 학생이 한명도 없을 확률

# (365-1)/365 * (365-2)/365 * (365-3)/365 * (365-4)/365 ..........(365-19)/365
# 결과는 약 58.9
n <- 40
res <- 1 
for (i in 1:(n-1)){
    res <- res * (365 - i) / 365 
}
res
